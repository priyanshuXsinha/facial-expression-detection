{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "a59c9144-ab85-4e00-820f-0b5addb95eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import model_from_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "772b661e-001d-4d4c-9d01-098c32004532",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR='images/train' \n",
    "TEST_DIR='images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "0a879250-361b-4ccf-9cda-8bc8b35fe0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def createdataframe(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        # skip hidden files (like .DS_Store)\n",
    "        if label.startswith('.'):\n",
    "            continue  \n",
    "        folder_path = os.path.join(dir, label)\n",
    "        for imagename in os.listdir(folder_path):\n",
    "            if imagename.startswith('.'):  # skip hidden files inside as error due to .DS_Store\n",
    "                continue\n",
    "            image_paths.append(os.path.join(folder_path, imagename))\n",
    "            labels.append(label)\n",
    "    return image_paths, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "719c4b75-09bb-4ffc-8023-1ff8d95e57e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.DataFrame()\n",
    "train['image'], train['label']=createdataframe(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "52f77cdf-3a40-48ce-b466-b3d473b87b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                image    label\n",
      "0         images/train/happy/3578.jpg    happy\n",
      "1        images/train/happy/16988.jpg    happy\n",
      "2         images/train/happy/2666.jpg    happy\n",
      "3         images/train/happy/5109.jpg    happy\n",
      "4        images/train/happy/11981.jpg    happy\n",
      "...                               ...      ...\n",
      "28816  images/train/disgust/10112.jpg  disgust\n",
      "28817  images/train/disgust/21668.jpg  disgust\n",
      "28818   images/train/disgust/7049.jpg  disgust\n",
      "28819   images/train/disgust/9716.jpg  disgust\n",
      "28820   images/train/disgust/3561.jpg  disgust\n",
      "\n",
      "[28821 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "83d3b5b1-c390-45d1-b39a-4b5ff5c3dc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.DataFrame()\n",
    "test['image'], test['label']=createdataframe(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "3250ac05-0ff0-43ad-9a03-0f374f37a2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              image    label\n",
      "0       images/test/happy/23933.jpg    happy\n",
      "1       images/test/happy/24906.jpg    happy\n",
      "2       images/test/happy/18033.jpg    happy\n",
      "3       images/test/happy/15271.jpg    happy\n",
      "4       images/test/happy/26888.jpg    happy\n",
      "...                             ...      ...\n",
      "7061  images/test/disgust/20761.jpg  disgust\n",
      "7062  images/test/disgust/28710.jpg  disgust\n",
      "7063  images/test/disgust/23876.jpg  disgust\n",
      "7064   images/test/disgust/9460.jpg  disgust\n",
      "7065  images/test/disgust/35580.jpg  disgust\n",
      "\n",
      "[7066 rows x 2 columns]\n",
      "0         images/test/happy/23933.jpg\n",
      "1         images/test/happy/24906.jpg\n",
      "2         images/test/happy/18033.jpg\n",
      "3         images/test/happy/15271.jpg\n",
      "4         images/test/happy/26888.jpg\n",
      "                    ...              \n",
      "7061    images/test/disgust/20761.jpg\n",
      "7062    images/test/disgust/28710.jpg\n",
      "7063    images/test/disgust/23876.jpg\n",
      "7064     images/test/disgust/9460.jpg\n",
      "7065    images/test/disgust/35580.jpg\n",
      "Name: image, Length: 7066, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test)\n",
    "print(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "66e18a5d-fa8d-474e-bf87-b2a901b87a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "d3e5fcde-de87-46b7-8ea6-17aa1ea7e9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        # Ensure resizing\n",
    "        img = load_img(image, color_mode=\"grayscale\", target_size=(48,48))\n",
    "        img = img_to_array(img)   # shape (48,48,1)\n",
    "        features.append(img)\n",
    "\n",
    "    features = np.array(features)  \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "999c8cff-b18e-4394-a337-068287102e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd0b98737694e2d96c7009b9ca9c504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28821, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "train_features = extract_features(train['image'])\n",
    "print(train_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "74642b70-da20-49cb-aeda-39723d70df3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eccf73bbb067414d85dfd71753544623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7066 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_features = extract_features(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "525f1f33-3ec0-4cb2-be77-fab13b9fa6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=train_features/255.0                   #variables for image\n",
    "x_test=test_features/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "093503da-856d-4c1a-a08d-d886d3cc21ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder  #supervised learning as reaction is labelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "0583e621-9070-4c2b-b6b4-6348ffa3f22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-9 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-9 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-9 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-9 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-9 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-9 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-9 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-9 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-9 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LabelEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le=LabelEncoder() #object\n",
    "le.fit(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "c3559351-f1d4-4647-a0bd-454c4880632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=le.transform(train['label'])           # variables for label\n",
    "y_test=le.transform(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "2779085a-8d88-4f5a-836c-dab63645b683",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=to_categorical(y_train,num_classes=7)\n",
    "y_test=to_categorical(y_test,num_classes=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "b51d1a5f-9c86-43ee-886a-2c43070e39f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model=Sequential() #object\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Second conv block\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Third conv block\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Convolutional block\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Flatten\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Output layer (7 classes for facial expression recognition)\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "212c91f9-5a4e-4722-a545-52342d1de1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "2fa3006d-9bac-4290-b5f9-05fe41b2d853",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m 34/226\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40\u001b[0m 526ms/step - accuracy: 0.2040 - loss: 1.8831"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[396], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# TODO: respect compiled trainable state\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_epoch_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_split \u001b[38;5;129;01mand\u001b[39;00m validation_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;66;03m# Create the validation data using the training data. Only supported\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;66;03m# for TF/numpy/jax arrays.\u001b[39;00m\n\u001b[1;32m    323\u001b[0m     (\n\u001b[1;32m    324\u001b[0m         (x, y, sample_weight),\n\u001b[1;32m    325\u001b[0m         validation_data,\n\u001b[1;32m    326\u001b[0m     ) \u001b[38;5;241m=\u001b[39m array_slicing\u001b[38;5;241m.\u001b[39mtrain_validation_split(\n\u001b[1;32m    327\u001b[0m         (x, y, sample_weight), validation_split\u001b[38;5;241m=\u001b[39mvalidation_split\n\u001b[1;32m    328\u001b[0m     )\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=128,\n",
    "    epochs=100,\n",
    "    validation_data=(x_test, y_test)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "e25dfc93-4d29-40cc-a914-e0575018c482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"emotiondetector.json\",'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save(\"emotiondetector.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff04240a-fb20-47ce-a213-8ee92e1ac85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "6ee5cebe-9186-4e47-acc7-c72b45c44be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "# Load model architecture\n",
    "with open(\"facialemotionmodel.json\", \"r\") as json_file:\n",
    "    model_json = json_file.read()\n",
    "from tensorflow.keras.models import model_from_json, Sequential\n",
    "model = model_from_json(model_json, custom_objects={\"Sequential\": Sequential})\n",
    "model.load_weights(\"facialemotionmodel.h5\")\n",
    "\n",
    "print(\"✅ Model loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfb4f8a-0e4d-41a2-89ef-11e4148c1736",
   "metadata": {},
   "outputs": [],
   "source": [
    "label=['angry','disgust', 'fear', 'happy','neutral','sad','surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "84f109e5-2731-451d-85d9-2b37f50f8713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ef(image):\n",
    "    img = load_img(image, color_mode=\"grayscale\", target_size=(48,48))\n",
    "    feature = img_to_array(img)   # converts to numpy array\n",
    "    feature = feature.reshape(1,48,48,1) / 255.0  # normalize\n",
    "    return feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "4df8709f-7bb0-434c-a88c-8187520b421e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image is of sad\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "model prediction is  sad\n"
     ]
    }
   ],
   "source": [
    "image = 'images/train/sad/42.jpg'\n",
    "print(\"original image is of sad\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "8d256f22-0897-4883-ba3c-4fe053c4abfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "6d6256cc-9e00-4334-8001-1df081d48517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image is of sad\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "model prediction is  sad\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x36e31c410>"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = 'images/train/sad/42.jpg'\n",
    "print(\"original image is of sad\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201cf0d0-7482-4704-a90f-ef09fb5df159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
